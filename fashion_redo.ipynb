{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "%matplotlib inline\n",
    "from importlib import reload  # Python 3\n",
    "import utils_code; reload(utils_code)\n",
    "from utils_code import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data, get valid set and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (60000, 784)\n",
      "Testing set size: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "from utils import mnist_reader\n",
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "\n",
    "print('Training set size: {}'.format(X_train.shape))\n",
    "print('Testing set size: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (60000, 28, 28, 1)\n",
      "Testing set size: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "def reshape_img(x):\n",
    "#     x = x/255\n",
    "    return x.reshape(x.shape[0],28,28,1)\n",
    "X_train = reshape_img(X_train)\n",
    "X_test = reshape_img(X_test)\n",
    "print('Training set size: {}'.format(X_train.shape))\n",
    "print('Testing set size: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training set: (50000, 28, 28, 1)\n",
      "size of valid set: (10000, 28, 28, 1)\n",
      "size of test set: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_valid = X_train[50000:]\n",
    "y_valid = y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "y_train = y_train[:50000]\n",
    "print(\"size of training set: {}\".format(X_train.shape))\n",
    "print(\"size of valid set: {}\".format(X_valid.shape))\n",
    "print(\"size of test set: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = onehot(y_train)\n",
    "y_test = onehot(y_test)\n",
    "y_valid = onehot(y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels={\n",
    "    0:'T-shirt/top',\n",
    "    1:'Trouser',\n",
    "    2:'Pullover',\n",
    "    3:'Dress',\n",
    "    4:'Coat',\n",
    "    5:'Sandal',\n",
    "    6:'Shirt',\n",
    "    7:'Sneaker',\n",
    "    8:'Bag',\n",
    "    9:'Ankle boot',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.8022\n",
      "89.96\n"
     ]
    }
   ],
   "source": [
    "# normalization\n",
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "print(mean_px)\n",
    "print(std_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # apply normalization to test and valid set\n",
    "# X_valid = norm_input(X_valid)\n",
    "# X_test = norm_input(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply learning models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.initializers import VarianceScaling,glorot_normal\n",
    "def test_set_accuracy(model):\n",
    "    score = model.evaluate(X_test,y_test,verbose=1)\n",
    "    print()\n",
    "    print(score)\n",
    "    print('\\n', 'Accuracy on test set:', score[1])\n",
    "def get_initializer():\n",
    "    return VarianceScaling(seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lin_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(28,28,1)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = get_lin_model()\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = gen.flow(X_valid,y_valid,batch_size = batch_size)\n",
    "# test_batches = gen.flow(X_test, y_test, batch_size=batch_size)\n",
    "steps_per_epoch = int(np.ceil(batches.n/batch_size))\n",
    "validation_steps = int(np.ceil(val_batches.n/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "782/782 [==============================] - 3s - loss: 0.5775 - acc: 0.7941 - val_loss: 0.4956 - val_acc: 0.8269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efede1fd780>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 2s - loss: 0.4556 - acc: 0.8411 - val_loss: 0.4577 - val_acc: 0.8381\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 2s - loss: 0.4351 - acc: 0.8481 - val_loss: 0.4469 - val_acc: 0.8408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efedc173a20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.1\n",
    "lm.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=2, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 3s - loss: 0.4263 - acc: 0.8522 - val_loss: 0.4404 - val_acc: 0.8468\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 2s - loss: 0.4144 - acc: 0.8556 - val_loss: 0.4360 - val_acc: 0.8485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efedc173b38>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.001\n",
    "lm.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=2, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "782/782 [==============================] - 2s - loss: 0.4121 - acc: 0.8559 - val_loss: 0.4476 - val_acc: 0.8438\n",
      "Epoch 2/8\n",
      "782/782 [==============================] - 2s - loss: 0.4101 - acc: 0.8575 - val_loss: 0.4166 - val_acc: 0.8470\n",
      "Epoch 3/8\n",
      "782/782 [==============================] - 2s - loss: 0.3994 - acc: 0.8596 - val_loss: 0.4465 - val_acc: 0.8459\n",
      "Epoch 4/8\n",
      "782/782 [==============================] - 2s - loss: 0.3958 - acc: 0.8620 - val_loss: 0.4340 - val_acc: 0.8481\n",
      "Epoch 5/8\n",
      "782/782 [==============================] - 2s - loss: 0.3996 - acc: 0.8599 - val_loss: 0.4438 - val_acc: 0.8459\n",
      "Epoch 6/8\n",
      "782/782 [==============================] - 2s - loss: 0.3949 - acc: 0.8612 - val_loss: 0.4497 - val_acc: 0.8406\n",
      "Epoch 7/8\n",
      "782/782 [==============================] - 2s - loss: 0.3929 - acc: 0.8636 - val_loss: 0.4486 - val_acc: 0.8454\n",
      "Epoch 8/8\n",
      "782/782 [==============================] - 2s - loss: 0.3918 - acc: 0.8622 - val_loss: 0.4321 - val_acc: 0.8483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efedc173f60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.01\n",
    "lm.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=8, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "782/782 [==============================] - 2s - loss: 0.3868 - acc: 0.8639 - val_loss: 0.4444 - val_acc: 0.8395\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 2s - loss: 0.3848 - acc: 0.8650 - val_loss: 0.4368 - val_acc: 0.8454\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 2s - loss: 0.3855 - acc: 0.8645 - val_loss: 0.4465 - val_acc: 0.8447\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 2s - loss: 0.3855 - acc: 0.8643 - val_loss: 0.4594 - val_acc: 0.8429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efedc173d30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.001\n",
    "lm.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=4, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9696/10000 [============================>.] - ETA: 0s\n",
      "[0.47907687935829163, 0.8347]\n",
      "\n",
      " Accuracy on test set: 0.8347\n"
     ]
    }
   ],
   "source": [
    "test_set_accuracy(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network with 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def neural_net():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(28,28,1)),\n",
    "        Flatten(),\n",
    "        Dense(512,activation='relu',kernel_initializer = get_initializer()),\n",
    "        Dense(10, activation='softmax',kernel_initializer = get_initializer())\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = neural_net()\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = gen.flow(X_valid,y_valid,batch_size = batch_size)\n",
    "# test_batches = gen.flow(X_test, y_test, batch_size=batch_size)\n",
    "steps_per_epoch = int(np.ceil(batches.n/batch_size))\n",
    "validation_steps = int(np.ceil(val_batches.n/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 3s - loss: 0.4540 - acc: 0.8365 - val_loss: 0.3751 - val_acc: 0.8640\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 3s - loss: 0.3478 - acc: 0.8732 - val_loss: 0.3395 - val_acc: 0.8746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efedc9f0978>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=2, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "782/782 [==============================] - 3s - loss: 0.3112 - acc: 0.8867 - val_loss: 0.3411 - val_acc: 0.8750\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 3s - loss: 0.2853 - acc: 0.8928 - val_loss: 0.3355 - val_acc: 0.8805\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 3s - loss: 0.2629 - acc: 0.9014 - val_loss: 0.3374 - val_acc: 0.8834\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 3s - loss: 0.2453 - acc: 0.9081 - val_loss: 0.3691 - val_acc: 0.8706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efede0a5ba8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.optimizer.lr=0.01\n",
    "nn.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=4, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "782/782 [==============================] - 3s - loss: 0.2368 - acc: 0.9119 - val_loss: 0.3355 - val_acc: 0.8844\n",
      "Epoch 2/8\n",
      "782/782 [==============================] - 3s - loss: 0.2222 - acc: 0.9176 - val_loss: 0.3268 - val_acc: 0.8840\n",
      "Epoch 3/8\n",
      "782/782 [==============================] - 3s - loss: 0.2111 - acc: 0.9211 - val_loss: 0.3282 - val_acc: 0.8879\n",
      "Epoch 4/8\n",
      "782/782 [==============================] - 3s - loss: 0.1968 - acc: 0.9261 - val_loss: 0.3487 - val_acc: 0.8903\n",
      "Epoch 5/8\n",
      "782/782 [==============================] - 3s - loss: 0.1867 - acc: 0.9305 - val_loss: 0.3695 - val_acc: 0.8816\n",
      "Epoch 6/8\n",
      "782/782 [==============================] - 3s - loss: 0.1811 - acc: 0.9325 - val_loss: 0.3475 - val_acc: 0.8863\n",
      "Epoch 7/8\n",
      "782/782 [==============================] - 3s - loss: 0.1695 - acc: 0.9360 - val_loss: 0.3453 - val_acc: 0.8901\n",
      "Epoch 8/8\n",
      "782/782 [==============================] - 3s - loss: 0.1624 - acc: 0.9378 - val_loss: 0.3590 - val_acc: 0.8884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efede0bc828>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.optimizer.lr=0.001\n",
    "nn.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=8, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 3s - loss: 0.1579 - acc: 0.9407 - val_loss: 0.3698 - val_acc: 0.8902\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 3s - loss: 0.1469 - acc: 0.9449 - val_loss: 0.3780 - val_acc: 0.8893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efede0bcb70>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.optimizer.lr=0.0001\n",
    "nn.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=2, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9664/10000 [===========================>..] - ETA: 0s\n",
      "[0.40129989824891088, 0.88639999999999997]\n",
      "\n",
      " Accuracy on test set: 0.8864\n"
     ]
    }
   ],
   "source": [
    "test_set_accuracy(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lenet 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_initializer():\n",
    "    return VarianceScaling(seed=1204)\n",
    "\n",
    "def lenet():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(28,28,1)),\n",
    "        Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',\\\n",
    "\n",
    "              ),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(filters=64,kernel_size=3,padding='same',activation='relu',\\\n",
    "\n",
    "                     ),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(1024,activation='relu',\\\n",
    "\n",
    "                   ),\n",
    "        Dense(10,activation='softmax',\\\n",
    "\n",
    "                   )\n",
    "                    \n",
    "    ])\n",
    "    model.summary()\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_21 (Lambda)           (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,241,354\n",
      "Trainable params: 3,241,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ln = lenet()\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = gen.flow(X_valid,y_valid,batch_size = batch_size)\n",
    "# test_batches = gen.flow(X_test, y_test, batch_size=batch_size)\n",
    "steps_per_epoch = int(np.ceil(batches.n/batch_size))\n",
    "validation_steps = int(np.ceil(val_batches.n/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9568/10000 [===========================>..] - ETA: 0s\n",
      "[0.42563023577937859, 0.91820000000000002]\n",
      "\n",
      " Accuracy on test set: 0.9182\n"
     ]
    }
   ],
   "source": [
    "test_set_accuracy(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "782/782 [==============================] - 10s - loss: 0.3785 - acc: 0.8631 - val_loss: 0.2729 - val_acc: 0.8987\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 10s - loss: 0.2429 - acc: 0.9097 - val_loss: 0.2440 - val_acc: 0.9103\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 10s - loss: 0.1930 - acc: 0.9293 - val_loss: 0.2177 - val_acc: 0.9188\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 10s - loss: 0.1565 - acc: 0.9423 - val_loss: 0.2270 - val_acc: 0.9177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efed758f860>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=4, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 10s - loss: 0.1233 - acc: 0.9553 - val_loss: 0.2252 - val_acc: 0.9226\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 10s - loss: 0.0976 - acc: 0.9635 - val_loss: 0.2789 - val_acc: 0.9141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efed71882e8>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln.optimizer.lr=0.00001\n",
    "ln.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=2, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 10s - loss: 0.0772 - acc: 0.9712 - val_loss: 0.2693 - val_acc: 0.9210\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 10s - loss: 0.0584 - acc: 0.9793 - val_loss: 0.2980 - val_acc: 0.9174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efed758f4a8>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln.optimizer.lr=0.01\n",
    "ln.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=2, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9952/10000 [============================>.] - ETA: 0s\n",
      "[0.31714670702964065, 0.92069999999999996]\n",
      "\n",
      " Accuracy on test set: 0.9207\n"
     ]
    }
   ],
   "source": [
    "test_set_accuracy(ln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_vgg():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(28,28,1)),\n",
    "        Conv2D(32,(3,3), activation='relu'),\n",
    "        Conv2D(32,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64,(3,3), activation='relu'),\n",
    "        Conv2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = basic_vgg()\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = gen.flow(X_valid,y_valid,batch_size = batch_size)\n",
    "# test_batches = gen.flow(X_test, y_test, batch_size=batch_size)\n",
    "steps_per_epoch = int(np.ceil(batches.n/batch_size))\n",
    "validation_steps = int(np.ceil(val_batches.n/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 11s - loss: 0.4481 - acc: 0.8361 - val_loss: 0.3211 - val_acc: 0.8816\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 10s - loss: 0.2739 - acc: 0.8994 - val_loss: 0.2722 - val_acc: 0.8974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efed6a6c400>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=2, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "782/782 [==============================] - 11s - loss: 0.2264 - acc: 0.9160 - val_loss: 0.2944 - val_acc: 0.9021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efed67418d0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.optimizer.lr=0.1\n",
    "vgg.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "782/782 [==============================] - 10s - loss: 0.1925 - acc: 0.9292 - val_loss: 0.2384 - val_acc: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efed6ab4b70>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.optimizer.lr=0.01\n",
    "vgg.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 10s - loss: 0.1667 - acc: 0.9384 - val_loss: 0.2571 - val_acc: 0.9169\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 10s - loss: 0.1423 - acc: 0.9461 - val_loss: 0.2363 - val_acc: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efed6a60f60>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.optimizer.lr=0.001\n",
    "vgg.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=2, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 10s - loss: 0.1213 - acc: 0.9554 - val_loss: 0.2433 - val_acc: 0.9194\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 10s - loss: 0.1024 - acc: 0.9620 - val_loss: 0.2753 - val_acc: 0.9194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efeddab37f0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=2, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "782/782 [==============================] - 10s - loss: 0.0825 - acc: 0.9690 - val_loss: 0.3017 - val_acc: 0.9182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efed6a6c2e8>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.optimizer.lr=0.00001\n",
    "vgg.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "782/782 [==============================] - 10s - loss: 0.0739 - acc: 0.9724 - val_loss: 0.3261 - val_acc: 0.9141\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 10s - loss: 0.0616 - acc: 0.9771 - val_loss: 0.3271 - val_acc: 0.9179\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 10s - loss: 0.0529 - acc: 0.9800 - val_loss: 0.3606 - val_acc: 0.9196\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 10s - loss: 0.0459 - acc: 0.9831 - val_loss: 0.3671 - val_acc: 0.9189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efed6a6c198>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.optimizer.lr=0.000001\n",
    "vgg.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=4, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "782/782 [==============================] - 10s - loss: 0.0302 - acc: 0.9893 - val_loss: 0.4721 - val_acc: 0.9172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efed6589d30>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.optimizer.lr=0.001\n",
    "vgg.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9856/10000 [============================>.] - ETA: 0s\n",
      "[0.4972336398329586, 0.91100000000000003]\n",
      "\n",
      " Accuracy on test set: 0.911\n"
     ]
    }
   ],
   "source": [
    "test_set_accuracy(vgg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt         \n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "def plot_image_augmentation(gen):\n",
    "    for X_batch, y_batch in gen.flow(X_train, y_train, batch_size=9):\n",
    "        # create a grid of 3x3 images\n",
    "        for i in range(0, 9):\n",
    "            plt.subplot(330 + 1 + i)\n",
    "            plt.imshow(np.squeeze(X_batch[i]), cmap=cm.binary)\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# since image is already center and not rotating\n",
    "gen = image.ImageDataGenerator(\n",
    "                                shear_range=0.3,\n",
    "#                                horizontal_flip=True\n",
    "#                                 zoom_range=0.08\n",
    "                                )\n",
    "gen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncZwS/H8XIohHpKGw4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17dd0bf9b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image_augmentation(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = basic_vgg()\n",
    "gen = image.ImageDataGenerator(\n",
    "                                shear_range=0.3,\n",
    "#                                fill_mode='constant'\n",
    "#                                 zoom_range=0.08\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = gen.flow(X_valid, y_valid, batch_size=batch_size)\n",
    "steps_per_epoch = int(np.ceil(batches.n/batch_size))\n",
    "validation_steps = int(np.ceil(valid_batches.n/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 11s - loss: 0.4744 - acc: 0.8270 - val_loss: 0.3655 - val_acc: 0.8660\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 8s - loss: 0.2996 - acc: 0.8900 - val_loss: 0.2825 - val_acc: 0.8952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d801ddf98>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=2, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "782/782 [==============================] - 8s - loss: 0.2535 - acc: 0.9074 - val_loss: 0.2807 - val_acc: 0.8979\n",
      "Epoch 2/6\n",
      "782/782 [==============================] - 8s - loss: 0.2289 - acc: 0.9151 - val_loss: 0.2575 - val_acc: 0.9073\n",
      "Epoch 3/6\n",
      "782/782 [==============================] - 7s - loss: 0.2048 - acc: 0.9249 - val_loss: 0.2512 - val_acc: 0.9111\n",
      "Epoch 4/6\n",
      "782/782 [==============================] - 8s - loss: 0.1882 - acc: 0.9297 - val_loss: 0.2675 - val_acc: 0.9051\n",
      "Epoch 5/6\n",
      "782/782 [==============================] - 8s - loss: 0.1729 - acc: 0.9354 - val_loss: 0.2419 - val_acc: 0.9129\n",
      "Epoch 6/6\n",
      "782/782 [==============================] - 8s - loss: 0.1573 - acc: 0.9405 - val_loss: 0.2363 - val_acc: 0.9233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17dd4d6e358>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.optimizer.lr=0.01\n",
    "vgg.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=6, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "782/782 [==============================] - 8s - loss: 0.1410 - acc: 0.9469 - val_loss: 0.2601 - val_acc: 0.9139\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 8s - loss: 0.1283 - acc: 0.9518 - val_loss: 0.2429 - val_acc: 0.9220\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 8s - loss: 0.1173 - acc: 0.9555 - val_loss: 0.2584 - val_acc: 0.9192\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 8s - loss: 0.1079 - acc: 0.9599 - val_loss: 0.2688 - val_acc: 0.9179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d822efcf8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.optimizer.lr=0.001\n",
    "vgg.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=4, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "782/782 [==============================] - 7s - loss: 0.1007 - acc: 0.9622 - val_loss: 0.2758 - val_acc: 0.9138\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 7s - loss: 0.0886 - acc: 0.9661 - val_loss: 0.3077 - val_acc: 0.9173\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 8s - loss: 0.0828 - acc: 0.9694 - val_loss: 0.3039 - val_acc: 0.9180\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 8s - loss: 0.0787 - acc: 0.9707 - val_loss: 0.3057 - val_acc: 0.9204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d822ef7f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.optimizer.lr=0.00001\n",
    "vgg.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=4, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 8s - loss: 0.0751 - acc: 0.9720 - val_loss: 0.3435 - val_acc: 0.9191\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 8s - loss: 0.0695 - acc: 0.9734 - val_loss: 0.3349 - val_acc: 0.9143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d822efc18>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.optimizer.lr=0.000001\n",
    "vgg.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=2, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9344/10000 [===========================>..] - ETA: 0s\n",
      "[0.34395054425001143, 0.91720000000000002]\n",
      "\n",
      " Accuracy on test set: 0.9172\n"
     ]
    }
   ],
   "source": [
    "test_set_accuracy(vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best accuracy for test set is 0.9222 at shear_range=0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_bn():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(28,28,1)),\n",
    "        Conv2D(32,(3,3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32,(3,3), activation='relu'),\n",
    "\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "#         BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vggbn = vgg_bn()\n",
    "gen = image.ImageDataGenerator(shear_range=0.3)\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = gen.flow(X_valid,y_valid,batch_size = batch_size)\n",
    "# test_batches = gen.flow(X_test, y_test, batch_size=batch_size)\n",
    "steps_per_epoch = int(np.ceil(batches.n/batch_size))\n",
    "validation_steps = int(np.ceil(val_batches.n/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "782/782 [==============================] - 11s - loss: 0.5149 - acc: 0.8094 - val_loss: 0.4239 - val_acc: 0.8506\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 11s - loss: 0.3639 - acc: 0.8676 - val_loss: 0.3707 - val_acc: 0.8661\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 11s - loss: 0.3186 - acc: 0.8847 - val_loss: 0.3231 - val_acc: 0.8831\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 11s - loss: 0.2924 - acc: 0.8943 - val_loss: 0.3030 - val_acc: 0.8922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d96b217b8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggbn.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=4, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "782/782 [==============================] - 11s - loss: 0.2746 - acc: 0.8996 - val_loss: 0.3444 - val_acc: 0.8816\n",
      "Epoch 2/8\n",
      "782/782 [==============================] - 11s - loss: 0.2615 - acc: 0.9046 - val_loss: 0.3195 - val_acc: 0.8876\n",
      "Epoch 3/8\n",
      "782/782 [==============================] - 11s - loss: 0.2423 - acc: 0.9115 - val_loss: 0.3043 - val_acc: 0.8908\n",
      "Epoch 4/8\n",
      "782/782 [==============================] - 11s - loss: 0.2316 - acc: 0.9153 - val_loss: 0.2915 - val_acc: 0.8937\n",
      "Epoch 5/8\n",
      "782/782 [==============================] - 10s - loss: 0.2202 - acc: 0.9197 - val_loss: 0.3132 - val_acc: 0.8936\n",
      "Epoch 6/8\n",
      "782/782 [==============================] - 11s - loss: 0.2160 - acc: 0.9205 - val_loss: 0.3158 - val_acc: 0.8913\n",
      "Epoch 7/8\n",
      "782/782 [==============================] - 10s - loss: 0.2047 - acc: 0.9252 - val_loss: 0.2813 - val_acc: 0.9029\n",
      "Epoch 8/8\n",
      "782/782 [==============================] - 10s - loss: 0.1985 - acc: 0.9269 - val_loss: 0.2987 - val_acc: 0.8959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d96b21828>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggbn.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=8, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "782/782 [==============================] - 13s - loss: 0.1895 - acc: 0.9295 - val_loss: 0.2919 - val_acc: 0.8995\n",
      "Epoch 2/6\n",
      "782/782 [==============================] - 13s - loss: 0.1819 - acc: 0.9326 - val_loss: 0.3299 - val_acc: 0.8895\n",
      "Epoch 3/6\n",
      "782/782 [==============================] - 13s - loss: 0.1750 - acc: 0.9355 - val_loss: 0.2943 - val_acc: 0.9011\n",
      "Epoch 4/6\n",
      "782/782 [==============================] - 13s - loss: 0.1711 - acc: 0.9360 - val_loss: 0.3109 - val_acc: 0.8956\n",
      "Epoch 5/6\n",
      "782/782 [==============================] - 13s - loss: 0.1650 - acc: 0.9404 - val_loss: 0.3201 - val_acc: 0.8964\n",
      "Epoch 6/6\n",
      "782/782 [==============================] - 14s - loss: 0.1606 - acc: 0.9413 - val_loss: 0.3068 - val_acc: 0.9046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d94be29e8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggbn.optimizer.lr=0.00001\n",
    "vggbn.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=6, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "782/782 [==============================] - 19s - loss: 0.1460 - acc: 0.9462 - val_loss: 0.2748 - val_acc: 0.9132\n",
      "Epoch 2/8\n",
      "782/782 [==============================] - 19s - loss: 0.1418 - acc: 0.9478 - val_loss: 0.3038 - val_acc: 0.9085\n",
      "Epoch 3/8\n",
      "782/782 [==============================] - 19s - loss: 0.1365 - acc: 0.9485 - val_loss: 0.2955 - val_acc: 0.9081\n",
      "Epoch 4/8\n",
      "782/782 [==============================] - 19s - loss: 0.1320 - acc: 0.9510 - val_loss: 0.2802 - val_acc: 0.9167\n",
      "Epoch 5/8\n",
      "782/782 [==============================] - 19s - loss: 0.1299 - acc: 0.9534 - val_loss: 0.2909 - val_acc: 0.9117\n",
      "Epoch 6/8\n",
      "782/782 [==============================] - 19s - loss: 0.1251 - acc: 0.9530 - val_loss: 0.3282 - val_acc: 0.9024\n",
      "Epoch 7/8\n",
      "782/782 [==============================] - 19s - loss: 0.1216 - acc: 0.9546 - val_loss: 0.2995 - val_acc: 0.9113\n",
      "Epoch 8/8\n",
      "782/782 [==============================] - 19s - loss: 0.1184 - acc: 0.9560 - val_loss: 0.3274 - val_acc: 0.9068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efe8b1e6e80>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggbn.optimizer.lr=0.00001\n",
    "vggbn.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=8, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9792/10000 [============================>.] - ETA: 0s\n",
      "[0.29696623489856722, 0.90610000000000002]\n",
      "\n",
      " Accuracy on test set: 0.9061\n"
     ]
    }
   ],
   "source": [
    "test_set_accuracy(vggbn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_bn_drop():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(28,28,1)),\n",
    "        Conv2D(32,(3,3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32,(3,3), activation='relu'),\n",
    "\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "#         BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "vggbndrop = vgg_bn_drop()\n",
    "gen = image.ImageDataGenerator(shear_range=0.3)\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = gen.flow(X_valid,y_valid,batch_size = batch_size)\n",
    "# test_batches = gen.flow(X_test, y_test, batch_size=batch_size)\n",
    "steps_per_epoch = int(np.ceil(batches.n/batch_size))\n",
    "validation_steps = int(np.ceil(val_batches.n/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 13s - loss: 0.5748 - acc: 0.7910 - val_loss: 0.4447 - val_acc: 0.8413\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 11s - loss: 0.3914 - acc: 0.8597 - val_loss: 0.3802 - val_acc: 0.8673\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 11s - loss: 0.3387 - acc: 0.8776 - val_loss: 0.3151 - val_acc: 0.8849\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 11s - loss: 0.3069 - acc: 0.8895 - val_loss: 0.3197 - val_acc: 0.8829\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 11s - loss: 0.2870 - acc: 0.8958 - val_loss: 0.3371 - val_acc: 0.8796\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 11s - loss: 0.2687 - acc: 0.9030 - val_loss: 0.3316 - val_acc: 0.8777\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 11s - loss: 0.2523 - acc: 0.9086 - val_loss: 0.3561 - val_acc: 0.8731\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 11s - loss: 0.2431 - acc: 0.9118 - val_loss: 0.3013 - val_acc: 0.8964\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 12s - loss: 0.2302 - acc: 0.9159 - val_loss: 0.2955 - val_acc: 0.8966\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 12s - loss: 0.2214 - acc: 0.9202 - val_loss: 0.3064 - val_acc: 0.8931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d94c07080>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggbndrop.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=10, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "782/782 [==============================] - 10s - loss: 0.2152 - acc: 0.9217 - val_loss: 0.3048 - val_acc: 0.8972\n",
      "Epoch 2/6\n",
      "782/782 [==============================] - 10s - loss: 0.2033 - acc: 0.9267 - val_loss: 0.3094 - val_acc: 0.8967\n",
      "Epoch 3/6\n",
      "782/782 [==============================] - 10s - loss: 0.2008 - acc: 0.9269 - val_loss: 0.2783 - val_acc: 0.9030\n",
      "Epoch 4/6\n",
      "782/782 [==============================] - 10s - loss: 0.1918 - acc: 0.9313 - val_loss: 0.3463 - val_acc: 0.8805\n",
      "Epoch 5/6\n",
      "782/782 [==============================] - 10s - loss: 0.1829 - acc: 0.9330 - val_loss: 0.3277 - val_acc: 0.8922\n",
      "Epoch 6/6\n",
      "782/782 [==============================] - 10s - loss: 0.1798 - acc: 0.9344 - val_loss: 0.2835 - val_acc: 0.9051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f9fe26198>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggbndrop.optimizer.lr=0.0001\n",
    "vggbndrop.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=6, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 10s - loss: 0.1714 - acc: 0.9373 - val_loss: 0.2840 - val_acc: 0.9020\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 10s - loss: 0.1670 - acc: 0.9390 - val_loss: 0.2969 - val_acc: 0.8979\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 10s - loss: 0.1671 - acc: 0.9394 - val_loss: 0.3278 - val_acc: 0.8926\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 10s - loss: 0.1577 - acc: 0.9416 - val_loss: 0.3217 - val_acc: 0.9019\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 10s - loss: 0.1558 - acc: 0.9427 - val_loss: 0.2979 - val_acc: 0.9020\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 11s - loss: 0.1478 - acc: 0.9452 - val_loss: 0.2827 - val_acc: 0.9098\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 11s - loss: 0.1473 - acc: 0.9466 - val_loss: 0.2993 - val_acc: 0.9045\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 11s - loss: 0.1442 - acc: 0.9473 - val_loss: 0.2987 - val_acc: 0.9043\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 10s - loss: 0.1381 - acc: 0.9493 - val_loss: 0.3222 - val_acc: 0.8965\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 10s - loss: 0.1393 - acc: 0.9498 - val_loss: 0.2970 - val_acc: 0.9062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f9fe26048>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggbndrop.optimizer.lr=0.000001\n",
    "vggbndrop.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=10, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "782/782 [==============================] - 10s - loss: 0.1321 - acc: 0.9517 - val_loss: 0.3276 - val_acc: 0.9001\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 11s - loss: 0.1281 - acc: 0.9534 - val_loss: 0.3144 - val_acc: 0.9010\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 10s - loss: 0.1277 - acc: 0.9537 - val_loss: 0.3383 - val_acc: 0.8993\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 12s - loss: 0.1250 - acc: 0.9537 - val_loss: 0.3267 - val_acc: 0.8997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f9fe262b0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggbndrop.optimizer.lr=0.0000001\n",
    "vggbndrop.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=4, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9696/10000 [============================>.] - ETA: 0s\n",
      "[0.33883959484398363, 0.90069999999999995]\n",
      "\n",
      " Accuracy on test set: 0.9007\n"
     ]
    }
   ],
   "source": [
    "test_set_accuracy(vggbndrop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
